experiment:
  name: "baseline_001"
  date: "2024-01-17"
  description: "500 Examples"

environment:
  platform: "Lambda Labs H100"
  gpu_memory: "80GB"
  python_version: "3.9"
  base_model: "openai/whisper-base"

dataset:
  source: "pauljunsukhan/throatmic_codered"
  total_examples: 506
  train_split: 404
  test_split: 102
  audio:
    sampling_rate: 16000
    duration: "~10 seconds"
    format: "throat microphone"
    normalize: false

training:
  batch_size: 32
  eval_batch_size: 64
  gradient_accumulation_steps: 1
  learning_rate: 1e-5
  warmup_steps: 200
  lr_scheduler_type: "linear"
  max_steps: 1000
  gradient_checkpointing: false
  max_grad_norm: 1.0 #default
  fp16: true
  evaluation_strategy: "steps"
  eval_steps: 100
  save_steps: 100
  logging_steps: 25
  save_total_limit: 3
  push_to_hub: false
  predict_with_generate: true
  load_best_model_at_end: true
  metric_for_best_model: "wer"
  greater_is_better: false
  report_to: ["tensorboard"]
  monitoring:
    gradient_history_size: 1000
    significant_change_threshold: 1.0
    log_top_n_gradients: 5
  generation:
    language: "en"
    task: "transcribe"
    use_cache: false
    max_length: 225
  regularization:
    weight_decay: 0.0
    dropout: 0.0
    label_smoothing: 0.0

evaluation:
  early_stopping:
    enabled: true
    metric: "WER"
    mode: "min"
    patience: 5
  metric: "WER"